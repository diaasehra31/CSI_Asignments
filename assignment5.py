# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jAsjCpPDOSTg6-pLIZQNJxsv8gL1Wh1R
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import RidgeCV
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import mean_squared_error
import xgboost as xgb

train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')
train_ID = train['Id']; test_ID = test['Id']
train.drop(['Id'], axis=1, inplace=True)
test.drop(['Id'], axis=1, inplace=True)

train["SalePrice_Log"] = np.log1p(train["SalePrice"])
y = train["SalePrice_Log"]
train.drop(["SalePrice"], axis=1, inplace=True)

all_data = pd.concat([train.drop("SalePrice_Log",axis=1), test], axis=0).reset_index(drop=True)

threshold = len(all_data) * 0.7
all_data = all_data.loc[:, all_data.isnull().sum() < threshold]

num_cols = all_data.select_dtypes(include=['int64','float64']).columns
cat_cols = all_data.select_dtypes(include=['object']).columns

for col in num_cols:
    all_data[col] = all_data[col].fillna(all_data[col].median())

for col in cat_cols:
    all_data[col] = all_data[col].fillna(all_data[col].mode()[0])

def add_features(df):
    df['HouseAge'] = df['YrSold'] - df['YearBuilt']
    df['RemodelAge'] = df['YrSold'] - df['YearRemodAdd']
    df['TotalSF'] = df['1stFlrSF'] + df['2ndFlrSF'] + df['TotalBsmtSF']
    df['GrLivArea_OverallQual'] = df['GrLivArea'] * df['OverallQual']
    df['GrLivArea^2'] = df['GrLivArea'] ** 2
    df['OverallQual^2'] = df['OverallQual'] ** 2
    return df

all_data = add_features(all_data)

all_data = pd.get_dummies(all_data, drop_first=True)

n_train = train.shape[0]
X = all_data.iloc[:n_train, :].copy()
X_test = all_data.iloc[n_train:, :].copy()

scaler = RobustScaler()
X_scaled = scaler.fit_transform(X)
X_test_scaled = scaler.transform(X_test)

alphas = [0.1, 1, 10, 100]
ridge = RidgeCV(alphas=alphas, cv=5)
ridge.fit(X_scaled, y)
y_pred_ridge = ridge.predict(X_scaled)
print("Ridge RMSE:", np.sqrt(mean_squared_error(y, y_pred_ridge)))

dtrain = xgb.DMatrix(X_scaled, label=y)
dtest = xgb.DMatrix(X_test_scaled)
params = {
    'objective': 'reg:squarederror',
    'learning_rate': 0.05,
    'max_depth': 4,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'eval_metric': 'rmse'
}
cv_results = xgb.cv(params, dtrain, num_boost_round=1000,
                    early_stopping_rounds=20, folds=5, metrics="rmse", seed=42)
best_nrounds = cv_results['test-rmse-mean'].idxmin()
print("XGB best rounds:", best_nrounds)
model_xgb = xgb.train(params, dtrain, num_boost_round=best_nrounds)
y_pred_xgb = model_xgb.predict(dtrain)
print("XGB RMSE:", np.sqrt(mean_squared_error(y, y_pred_xgb)))

blend = (y_pred_ridge + y_pred_xgb) / 2

final_preds = np.expm1(blend)
submission = pd.DataFrame({"Id": test_ID, "SalePrice": final_preds})
submission.to_csv("submission.csv", index=False)

